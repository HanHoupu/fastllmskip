{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Skip Evaluation\n",
    "\n",
    "在 GSM8K 上评测 Dual Cache + Token Skip 优化。\n",
    "\n",
    "**Token Skip 原理（新版）：**\n",
    "- 比较 h_{t-1} 与 h_{t-2}（上一 step 和上上一 step 的最终 hidden state）的 cosine similarity\n",
    "- 对于相似度 > threshold 的 token，**完全跳过**当前 step 的计算\n",
    "- 被跳过的 token 使用上一 step 的 KV cache\n",
    "- 被跳过的 token 下一步强制更新（防止误差累积）\n",
    "\n",
    "**与原版 KV Reuse 的区别：**\n",
    "- 原版：在 forward 中途判定，部分层 skip\n",
    "- 新版：在 forward 之前判定，整个 forward 都 skip\n",
    "\n",
    "**实验配置:**\n",
    "1. Baseline: Dual Cache（不使用 Token Skip）\n",
    "2. Token Skip + 不同 `skip_threshold` (0.90, 0.95, 0.99)\n",
    "3. Token Skip + 不同 `force_full_every_k` (0, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Set GPU (modify as needed)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "\n",
    "# Environment settings\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['HF_ALLOW_CODE_EVAL'] = '1'\n",
    "os.environ['HF_DATASETS_TRUST_REMOTE_CODE'] = 'true'\n",
    "\n",
    "# Change to llada directory\n",
    "os.chdir('llada')\n",
    "\n",
    "# Create log directory\n",
    "os.makedirs('nlogs', exist_ok=True)\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 快速测试 (limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "task = \"gsm8k\"\n",
    "fewshot = 3\n",
    "limit = 30\n",
    "gpu = 1\n",
    "\n",
    "# (skip_threshold, force_full_every_k, name)\n",
    "experiments = [\n",
    "    (None, None, \"baseline\"),\n",
    "    (0.95, 3, \"skip_th095_k3\"),\n",
    "    (0.95, 1, \"skip_th095_k1\"),  # K=1 应该等价于 baseline\n",
    "    (0.99, 3, \"skip_th099_k3\"),\n",
    "    (0.90, 3, \"skip_th090_k3\"),\n",
    "]\n",
    "\n",
    "for skip_threshold, force_k, name in experiments:\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = f\"nlogs/{task}_{name}_{timestamp}.log\"\n",
    "    \n",
    "    model_args = [\n",
    "        \"model_path='GSAI-ML/LLaDA-8B-Instruct'\",\n",
    "        \"gen_length=128\",\n",
    "        \"steps=32\",\n",
    "        \"block_length=32\",\n",
    "        \"threshold=0.9\",\n",
    "        \"use_cache=True\",\n",
    "        \"dual_cache=True\",\n",
    "        \"show_speed=True\",\n",
    "    ]\n",
    "    \n",
    "    if skip_threshold is not None:\n",
    "        model_args.extend([\n",
    "            \"token_skip=True\",\n",
    "            f\"skip_threshold={skip_threshold}\",\n",
    "            f\"force_full_every_k={force_k}\",\n",
    "        ])\n",
    "    else:\n",
    "        model_args.append(\"token_skip=False\")\n",
    "    \n",
    "    cmd = f\"\"\"CUDA_VISIBLE_DEVICES={gpu} accelerate launch eval_llada.py \\\\\n",
    "        --tasks {task} --num_fewshot {fewshot} --limit {limit} \\\\\n",
    "        --confirm_run_unsafe_code --model llada_dist \\\\\n",
    "        --model_args {','.join(model_args)}\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running: {name}\")\n",
    "    print(f\"Log file: {log_file}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    with open(log_file, 'w') as f:\n",
    "        result = subprocess.run(cmd, shell=True, stdout=f, stderr=subprocess.STDOUT, text=True)\n",
    "    \n",
    "    with open(log_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        print(\"Last 10 lines:\")\n",
    "        for line in lines[-10:]:\n",
    "            print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 并行完整测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "task = \"gsm8k\"\n",
    "fewshot = 4\n",
    "\n",
    "# (skip_threshold, force_full_every_k, gpu, name)\n",
    "configs = [\n",
    "    (None, None, 0, \"baseline\"),\n",
    "    (0.95, 3, 1, \"skip_th095_k3\"),\n",
    "    (0.95, 1, 2, \"skip_th095_k1\"),\n",
    "    (0.99, 3, 3, \"skip_th099_k3\"),\n",
    "]\n",
    "\n",
    "processes = []\n",
    "\n",
    "for skip_threshold, force_k, gpu, name in configs:\n",
    "    log_file = f\"nlogs/token_skip_{task}_{name}_{datetime.datetime.now():%F_%H-%M-%S}.log\"\n",
    "    \n",
    "    skip_args = f\"dual_cache=True\"\n",
    "    if skip_threshold is not None:\n",
    "        skip_args += f\",token_skip=True,skip_threshold={skip_threshold},force_full_every_k={force_k}\"\n",
    "    else:\n",
    "        skip_args += \",token_skip=False\"\n",
    "    \n",
    "    cmd = f\"\"\"CUDA_VISIBLE_DEVICES={gpu} accelerate launch eval_llada.py \\\\\n",
    "        --tasks {task} --num_fewshot {fewshot} \\\\\n",
    "        --confirm_run_unsafe_code --model llada_dist \\\\\n",
    "        --model_args model_path='GSAI-ML/LLaDA-8B-Instruct',gen_length=256,steps=256,block_length=32,threshold=0.9,{skip_args},show_speed=True \\\\\n",
    "        --output_path evals_results/token_skip/gsm8k-{name} --log_samples\"\"\"\n",
    "    \n",
    "    print(f\"GPU{gpu} running: {name}\")\n",
    "    p = subprocess.Popen(cmd, shell=True, stdout=open(log_file, \"w\"), stderr=subprocess.STDOUT)\n",
    "    processes.append((p, name, log_file))\n",
    "\n",
    "print(f\"\\n{len(processes)} tasks launched, waiting...\")\n",
    "\n",
    "for p, name, log in processes:\n",
    "    p.wait()\n",
    "    print(f\"{name} finished (exit code: {p.returncode})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "log_files = sorted(glob.glob(\"nlogs/token_skip_gsm8k*.log\"), key=os.path.getmtime, reverse=True)\n",
    "\n",
    "print(\"Token Skip GSM8K Results:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "results = []\n",
    "for log_file in log_files[:10]:\n",
    "    name = os.path.basename(log_file)\n",
    "    \n",
    "    with open(log_file, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Accuracy\n",
    "    acc_match = re.search(r'exact_match[,:\\|]?\\s*([\\d.]+)', content)\n",
    "    acc = float(acc_match.group(1)) * 100 if acc_match else None\n",
    "    \n",
    "    # Speed\n",
    "    speed_match = re.search(r'Tokens per second:\\s*([\\d.]+)', content)\n",
    "    speed = float(speed_match.group(1)) if speed_match else None\n",
    "    \n",
    "    # NFE\n",
    "    nfe_match = re.search(r'Total NFE is (\\d+)', content)\n",
    "    nfe = int(nfe_match.group(1)) if nfe_match else None\n",
    "    \n",
    "    # Time\n",
    "    time_match = re.search(r'Total time taken:\\s*([\\d.]+)', content)\n",
    "    time_sec = float(time_match.group(1)) if time_match else None\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': acc,\n",
    "        'tokens_per_sec': speed,\n",
    "        'total_nfe': nfe,\n",
    "        'time_sec': time_sec,\n",
    "    })\n",
    "\n",
    "print(f\"{'Name':<55} {'Acc%':<8} {'Tok/s':<10} {'NFE':<10} {'Time(s)':<10}\")\n",
    "print(\"-\" * 90)\n",
    "for r in results:\n",
    "    acc_str = f\"{r['accuracy']:.2f}\" if r['accuracy'] else \"N/A\"\n",
    "    speed_str = f\"{r['tokens_per_sec']:.1f}\" if r['tokens_per_sec'] else \"N/A\"\n",
    "    nfe_str = str(r['total_nfe']) if r['total_nfe'] else \"N/A\"\n",
    "    time_str = f\"{r['time_sec']:.1f}\" if r['time_sec'] else \"N/A\"\n",
    "    print(f\"{r['name']:<55} {acc_str:<8} {speed_str:<10} {nfe_str:<10} {time_str:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 手动运行（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single experiment\n",
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "skip_threshold = 0.95\n",
    "force_full_every_k = 3\n",
    "limit = 100\n",
    "gpu = 0\n",
    "\n",
    "name = f\"manual_th{int(skip_threshold*100)}_k{force_full_every_k}\" if skip_threshold else \"manual_baseline\"\n",
    "log_file = f\"nlogs/manual_token_skip_{name}_{datetime.datetime.now():%F_%H-%M-%S}.log\"\n",
    "\n",
    "skip_args = f\"dual_cache=True\"\n",
    "if skip_threshold is not None:\n",
    "    skip_args += f\",token_skip=True,skip_threshold={skip_threshold},force_full_every_k={force_full_every_k}\"\n",
    "else:\n",
    "    skip_args += \",token_skip=False\"\n",
    "\n",
    "cmd = f\"\"\"CUDA_VISIBLE_DEVICES={gpu} accelerate launch eval_llada.py \\\\\n",
    "    --tasks gsm8k --num_fewshot 5 --limit {limit} \\\\\n",
    "    --confirm_run_unsafe_code --model llada_dist \\\\\n",
    "    --model_args model_path='GSAI-ML/LLaDA-8B-Instruct',gen_length=256,steps=256,block_length=32,threshold=0.9,{skip_args},show_speed=True \\\\\n",
    "    --output_path evals_results/token_skip/manual-{name} --log_samples\"\"\"\n",
    "\n",
    "print(f\"Running: {name}\")\n",
    "print(f\"Log: {log_file}\")\n",
    "print(f\"Command: {cmd[:150]}...\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# p = subprocess.Popen(cmd, shell=True, stdout=open(log_file, \"w\"), stderr=subprocess.STDOUT)\n",
    "# p.wait()\n",
    "# print(f\"Finished (exit code: {p.returncode})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 快速查看最近日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# 查看最近的日志文件\n",
    "log_files = sorted(glob.glob(\"nlogs/*.log\"), key=os.path.getmtime, reverse=True)\n",
    "\n",
    "if log_files:\n",
    "    latest_log = log_files[0]\n",
    "    print(f\"Latest log: {latest_log}\")\n",
    "    print(\"=\"*60)\n",
    "    with open(latest_log, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        # 显示最后 20 行\n",
    "        for line in lines[-20:]:\n",
    "            print(line.rstrip())\n",
    "else:\n",
    "    print(\"No log files found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
