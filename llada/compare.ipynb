{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pianng/miniconda3/envs/dllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "from transformers import AutoTokenizer\n",
        "from model.modeling_llada import LLaDAModelLM\n",
        "from generate import generate_with_dual_cache, generate_with_dual_cache_tokenskip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  7.36it/s]\n"
          ]
        }
      ],
      "source": [
        "# 加载模型\n",
        "device = 'cuda'\n",
        "model = LLaDAModelLM.from_pretrained('GSAI-ML/LLaDA-8B-Instruct', torch_dtype=torch.bfloat16).to(device).eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained('GSAI-ML/LLaDA-8B-Instruct')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 准备输入\n",
        "prompt = \"Who is Newton, physics?\"\n",
        "m = [{\"role\": \"user\", \"content\": prompt}]\n",
        "text = tokenizer.apply_chat_template(m, add_generation_prompt=True, tokenize=False)\n",
        "input_ids = torch.tensor(tokenizer(text)['input_ids']).to(device).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline: 6.78s, NFE=71\n",
            "Isaac Newton was an English physicist and mathematician who made significant contributions to the development of classical mechanics and optics. He is best known for his laws of motion, which describe the motion of objects, and his law of universal gravitation, which explains the force of gravity between objects. Newton's work laid the foundation for modern physics and is considered one of the most influential figures in the history of science.\n"
          ]
        }
      ],
      "source": [
        "# 测试 baseline\n",
        "start = time.time()\n",
        "out1, nfe1 = generate_with_dual_cache(model, input_ids, steps=128, gen_length=128, block_length=32, threshold=0.9)\n",
        "t1 = time.time() - start\n",
        "ans1 = tokenizer.decode(out1[0, input_ids.shape[1]:], skip_special_tokens=True)\n",
        "print(f\"Baseline: {t1:.2f}s, NFE={nfe1}\")\n",
        "print(ans1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TokenSkip: 12.07s, NFE=71\n",
            "Isaac Newton was an English physicist and mathematician who made significant contributions to the development of classical mechanics and optics. He is best known for his laws of motion, which describe the motion of objects, and his law of universal gravitation, which explains the force of gravity between objects. Newton's work laid the foundation for modern physics and is considered one of the most influential figures in the history of science.\n",
            "out1.shape: torch.Size([1, 147])\n",
            "out2.shape: torch.Size([1, 147])\n",
            "input_ids.shape: torch.Size([1, 19])\n",
            "预期 gen_length: 128\n",
            "实际生成长度: 128\n"
          ]
        }
      ],
      "source": [
        "# 测试 tokenskip（超参可调）\n",
        "SKIP_LAYER_K = 18       # 判定用的前 K 层\n",
        "SKIP_THRESHOLD = 1  # 平均 cos sim 阈值\n",
        "SKIP_OUTLIER = 0.7     # 任意层低于此值则强制计算\n",
        "\n",
        "start = time.time()\n",
        "out2, nfe2 = generate_with_dual_cache_tokenskip(\n",
        "    model, input_ids, steps=128, gen_length=128, block_length=32, threshold=0.9,\n",
        "    skip_layer_k=SKIP_LAYER_K, skip_threshold=SKIP_THRESHOLD, skip_outlier=SKIP_OUTLIER\n",
        ")\n",
        "t2 = time.time() - start\n",
        "ans2 = tokenizer.decode(out2[0, input_ids.shape[1]:], skip_special_tokens=True)\n",
        "print(f\"TokenSkip: {t2:.2f}s, NFE={nfe2}\")\n",
        "print(ans2)\n",
        "# 检查输出形状\n",
        "print(f\"out1.shape: {out1.shape}\")  # baseline\n",
        "print(f\"out2.shape: {out2.shape}\")  # tokenskip\n",
        "print(f\"input_ids.shape: {input_ids.shape}\")\n",
        "print(f\"预期 gen_length: 128\")\n",
        "print(f\"实际生成长度: {out2.shape[1] - input_ids.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TokenSkip: 9.09s, NFE=68\n",
            "Isaac Newton was an English physicist, mathematician, and astronomer, and one of the most influential scientists of all time. He is best known for his work on classical mechanics, and his laws of motion and calculus are fundamental to modern physics physics. Newton's work laid the foundation for the development of modern mathematics and physics.\n",
            "out1.shape: torch.Size([1, 147])\n",
            "out2.shape: torch.Size([1, 147])\n",
            "input_ids.shape: torch.Size([1, 19])\n",
            "预期 gen_length: 128\n",
            "实际生成长度: 128\n"
          ]
        }
      ],
      "source": [
        "# 测试 tokenskip（超参可调）\n",
        "SKIP_LAYER_K = 16       # 判定用的前 K 层\n",
        "SKIP_THRESHOLD = 0.99  # 平均 cos sim 阈值\n",
        "SKIP_OUTLIER = 0.9     # 任意层低于此值则强制计算\n",
        "\n",
        "start = time.time()\n",
        "out2, nfe2 = generate_with_dual_cache_tokenskip(\n",
        "    model, input_ids, steps=128, gen_length=128, block_length=32, threshold=0.9,\n",
        "    skip_layer_k=SKIP_LAYER_K, skip_threshold=SKIP_THRESHOLD, skip_outlier=SKIP_OUTLIER\n",
        ")\n",
        "t2 = time.time() - start\n",
        "ans2 = tokenizer.decode(out2[0, input_ids.shape[1]:], skip_special_tokens=True)\n",
        "print(f\"TokenSkip: {t2:.2f}s, NFE={nfe2}\")\n",
        "print(ans2)\n",
        "# 检查输出形状\n",
        "print(f\"out1.shape: {out1.shape}\")  # baseline\n",
        "print(f\"out2.shape: {out2.shape}\")  # tokenskip\n",
        "print(f\"input_ids.shape: {input_ids.shape}\")\n",
        "print(f\"预期 gen_length: 128\")\n",
        "print(f\"实际生成长度: {out2.shape[1] - input_ids.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Isaac Newton was an English physicist, mathematician, and astronomer, and one of the most influential scientists of all time. He is best known for his work on classical mechanics, and his laws of motion and calculus are fundamental to modern physics physics. Newton's work laid the foundation for the development of modern mathematics and physics.\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ans2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Speedup: 0.75x\n",
            "NFE: 71 -> 68\n"
          ]
        }
      ],
      "source": [
        "# 对比\n",
        "print(f\"Speedup: {t1/t2:.2f}x\")\n",
        "print(f\"NFE: {nfe1} -> {nfe2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/30] strict=None, flex=1880.00, gold=2280, ✗\n",
            "[2/30] strict=None, flex=1, gold=1, ✓\n",
            "[3/30] strict=None, flex=5, gold=5, ✓\n",
            "[4/30] strict=None, flex=12, gold=12, ✓\n",
            "[5/30] strict=None, flex=364, gold=273, ✗\n",
            "[6/30] strict=None, flex=30, gold=45, ✗\n",
            "[7/30] strict=None, flex=3, gold=21, ✗\n",
            "[8/30] strict=None, flex=20, gold=145, ✗\n",
            "[9/30] strict=None, flex=60, gold=60, ✓\n",
            "[10/30] strict=None, flex=122, gold=122, ✓\n",
            "[11/30] strict=None, flex=None, gold=29, ✗\n",
            "[12/30] strict=None, flex=80, gold=80, ✓\n",
            "[13/30] strict=None, flex=6, gold=36, ✗\n",
            "[14/30] strict=None, flex=1300, gold=1430, ✗\n",
            "[15/30] strict=None, flex=7, gold=5, ✗\n",
            "[16/30] strict=None, flex=5, gold=5, ✓\n",
            "[17/30] strict=None, flex=5, gold=5, ✓\n",
            "[18/30] strict=None, flex=18, gold=66, ✗\n",
            "[19/30] strict=None, flex=15, gold=15, ✓\n",
            "[20/30] strict=None, flex=2, gold=40, ✗\n",
            "[21/30] strict=None, flex=93, gold=93, ✓\n",
            "[22/30] strict=None, flex=300, gold=2000, ✗\n",
            "[23/30] strict=None, flex=1520, gold=1520, ✓\n",
            "[24/30] strict=None, flex=170, gold=11050, ✗\n"
          ]
        }
      ],
      "source": [
        "# GSM8K 30题评估（tokenskip模式，复用已加载模型）\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "from datasets import load_dataset\n",
        "\n",
        "# TokenSkip 超参（与 cell 4 保持一致）\n",
        "SKIP_LAYER_K = 16\n",
        "SKIP_THRESHOLD = 0.99\n",
        "SKIP_OUTLIER = 0.9\n",
        "\n",
        "random.seed(42)\n",
        "gsm8k = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")\n",
        "gsm8k_30 = random.sample(list(gsm8k), 30)\n",
        "\n",
        "def extract_answer_strict(text):\n",
        "    \"\"\"严格提取: lm_eval regex = r'#### (\\-?[0-9\\.\\,]+)'\"\"\"\n",
        "    match = re.search(r'#### (-?[0-9.,]+)', text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "def extract_answer_flexible(text):\n",
        "    \"\"\"宽松提取: lm_eval regex = r'(-?[$0-9.,]{2,})|(-?[0-9]+)', 取最后一个\"\"\"\n",
        "    # 匹配所有数字模式\n",
        "    matches = re.findall(r'(-?\\$?[0-9.,]{2,})|(-?[0-9]+)', text)\n",
        "    # findall 返回 tuple list，展平并过滤空值\n",
        "    nums = [m[0] or m[1] for m in matches if m[0] or m[1]]\n",
        "    return nums[-1] if nums else None  # group_select: -1 取最后一个\n",
        "\n",
        "def get_gold_answer(answer_text):\n",
        "    \"\"\"从标准答案提取数字 (用 strict 方式)\"\"\"\n",
        "    match = re.search(r'#### (-?[0-9.,]+)', answer_text)\n",
        "    return match.group(1) if match else \"\"\n",
        "\n",
        "def normalize_answer(ans):\n",
        "    \"\"\"归一化答案: 移除 , $ 和末尾的 .\"\"\"\n",
        "    if ans is None:\n",
        "        return None\n",
        "    ans = str(ans).strip()\n",
        "    ans = ans.replace(',', '').replace('$', '')  # 移除逗号和美元符\n",
        "    ans = ans.rstrip('.')  # 移除末尾的点\n",
        "    return ans\n",
        "\n",
        "# 评估循环\n",
        "strict_correct = 0\n",
        "flexible_correct = 0\n",
        "results_list = []\n",
        "\n",
        "for i, item in enumerate(gsm8k_30):\n",
        "    question = item['question']\n",
        "    gold = normalize_answer(get_gold_answer(item['answer']))\n",
        "    \n",
        "    # 构造输入\n",
        "    m = [{\"role\": \"user\", \"content\": question}]\n",
        "    text = tokenizer.apply_chat_template(m, add_generation_prompt=True, tokenize=False)\n",
        "    input_ids = torch.tensor(tokenizer(text)['input_ids']).to(device).unsqueeze(0)\n",
        "    \n",
        "    # 生成 (tokenskip)\n",
        "    out, nfe = generate_with_dual_cache_tokenskip(\n",
        "        model, input_ids, steps=128, gen_length=256, block_length=32, threshold=0.9,\n",
        "        skip_layer_k=SKIP_LAYER_K, skip_threshold=SKIP_THRESHOLD, skip_outlier=SKIP_OUTLIER\n",
        "    )\n",
        "    ans_text = tokenizer.decode(out[0, input_ids.shape[1]:], skip_special_tokens=True)\n",
        "    \n",
        "    pred_strict = normalize_answer(extract_answer_strict(ans_text))\n",
        "    pred_flex = normalize_answer(extract_answer_flexible(ans_text))\n",
        "    \n",
        "    is_strict = (pred_strict == gold) if pred_strict else False\n",
        "    is_flex = (pred_flex == gold) if pred_flex else False\n",
        "    \n",
        "    strict_correct += is_strict\n",
        "    flexible_correct += is_flex\n",
        "    results_list.append({'pred_strict': pred_strict, 'pred_flex': pred_flex, 'gold': gold, 'strict': is_strict, 'flex': is_flex})\n",
        "    \n",
        "    symbol = '✓' if is_flex else '✗'\n",
        "    print(f\"[{i+1}/30] strict={pred_strict}, flex={pred_flex}, gold={gold}, {symbol}\")\n",
        "\n",
        "# 统计 + stderr (二项分布标准误)\n",
        "n = len(gsm8k_30)\n",
        "acc_strict = strict_correct / n\n",
        "acc_flex = flexible_correct / n\n",
        "stderr_strict = math.sqrt(acc_strict * (1 - acc_strict) / n)\n",
        "stderr_flex = math.sqrt(acc_flex * (1 - acc_flex) / n)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"GSM8K 评估结果 (n={n}, tokenskip k={SKIP_LAYER_K} t={SKIP_THRESHOLD})\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"| Metric           | Value  | Stderr |\")\n",
        "print(f\"|------------------|--------|--------|\")\n",
        "print(f\"| exact_match,flexible-extract | {acc_flex:.4f} | ±{stderr_flex:.4f} |\")\n",
        "print(f\"| exact_match,strict-match     | {acc_strict:.4f} | ±{stderr_strict:.4f} |\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dllm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
