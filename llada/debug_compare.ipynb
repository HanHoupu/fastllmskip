{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pianng/miniconda3/envs/dllm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from model.modeling_llada import LLaDAModelLM\n",
        "from generate import generate_with_dual_cache, generate_with_dual_cache_tokenskip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00,  8.80it/s]\n"
          ]
        }
      ],
      "source": [
        "# 加载模型\n",
        "device = 'cuda'\n",
        "model = LLaDAModelLM.from_pretrained('GSAI-ML/LLaDA-8B-Instruct', torch_dtype=torch.bfloat16).to(device).eval()\n",
        "tokenizer = AutoTokenizer.from_pretrained('GSAI-ML/LLaDA-8B-Instruct')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input length: 19\n"
          ]
        }
      ],
      "source": [
        "# 准备输入\n",
        "prompt = \"Who is Newton, physics?\"\n",
        "m = [{\"role\": \"user\", \"content\": prompt}]\n",
        "text = tokenizer.apply_chat_template(m, add_generation_prompt=True, tokenize=False)\n",
        "input_ids = torch.tensor(tokenizer(text)['input_ids']).to(device).unsqueeze(0)\n",
        "print(f\"Input length: {input_ids.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x shape: torch.Size([1, 147])\n"
          ]
        }
      ],
      "source": [
        "# ===== 单步 debug：只跑一个 block 的第一个 step =====\n",
        "# 这样可以追踪 model forward 的细节\n",
        "\n",
        "mask_id = 126336\n",
        "gen_length = 128\n",
        "block_length = 32\n",
        "\n",
        "# 初始化序列\n",
        "x = torch.full((1, input_ids.shape[1] + gen_length), mask_id, dtype=torch.long, device=device)\n",
        "x[:, :input_ids.shape[1]] = input_ids\n",
        "print(f\"x shape: {x.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline logits shape: torch.Size([1, 147, 126464])\n",
            "Baseline hidden_states: 33 layers\n",
            "First hidden shape: torch.Size([1, 147, 4096])\n"
          ]
        }
      ],
      "source": [
        "# ===== Baseline: 第一次 forward（无 skip）=====\n",
        "with torch.no_grad():\n",
        "    out_baseline = model(x, use_cache=True, output_hidden_states=True)\n",
        "\n",
        "print(f\"Baseline logits shape: {out_baseline.logits.shape}\")\n",
        "print(f\"Baseline hidden_states: {len(out_baseline.hidden_states)} layers\")\n",
        "print(f\"First hidden shape: {out_baseline.hidden_states[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skip logits shape: torch.Size([1, 147, 126464])\n",
            "Skip hidden_states: 33 layers\n"
          ]
        }
      ],
      "source": [
        "# ===== TokenSkip: 第一次 forward（有 skip 参数但 prev_hidden=None）=====\n",
        "with torch.no_grad():\n",
        "    out_skip = model(\n",
        "        x, use_cache=True, output_hidden_states=True,\n",
        "        skip_layer_k=8, skip_threshold=0.95, skip_outlier=0.7,\n",
        "        prev_hidden=None  # 第一次没有 prev\n",
        "    )\n",
        "\n",
        "print(f\"Skip logits shape: {out_skip.logits.shape}\")\n",
        "print(f\"Skip hidden_states: {len(out_skip.hidden_states)} layers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第一次 forward logits 最大差异: 0.000000\n",
            "应该接近 0（因为第一次 prev_hidden=None，不会 skip）\n"
          ]
        }
      ],
      "source": [
        "# ===== 对比第一次 forward 的 logits =====\n",
        "diff = (out_baseline.logits - out_skip.logits).abs().max()\n",
        "print(f\"第一次 forward logits 最大差异: {diff.item():.6f}\")\n",
        "print(f\"应该接近 0（因为第一次 prev_hidden=None，不会 skip）\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Block range: [19, 51)\n",
            "prev_hidden: 33 layers, shape torch.Size([1, 147, 4096])\n"
          ]
        }
      ],
      "source": [
        "# ===== 模拟第二次 forward（refinement step）=====\n",
        "# 用第一次的 hidden_states 作为 prev_hidden\n",
        "\n",
        "Lp = input_ids.shape[1]\n",
        "s, e = Lp, Lp + block_length  # 第一个 block 的范围\n",
        "\n",
        "# 构造 replace_position\n",
        "replace_position = torch.zeros_like(x, dtype=torch.bool)\n",
        "replace_position[:, s:e] = True\n",
        "\n",
        "past_kv = out_baseline.past_key_values\n",
        "prev_hidden = out_baseline.hidden_states\n",
        "\n",
        "print(f\"Block range: [{s}, {e})\")\n",
        "print(f\"prev_hidden: {len(prev_hidden)} layers, shape {prev_hidden[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline 2nd forward logits shape: torch.Size([1, 32, 126464])\n"
          ]
        }
      ],
      "source": [
        "# ===== Baseline: 第二次 forward =====\n",
        "with torch.no_grad():\n",
        "    out2_baseline = model(\n",
        "        x[:, s:e],\n",
        "        past_key_values=past_kv,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "print(f\"Baseline 2nd forward logits shape: {out2_baseline.logits.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skip 2nd forward logits shape: torch.Size([1, 32, 126464])\n"
          ]
        }
      ],
      "source": [
        "# ===== TokenSkip: 第二次 forward（有 prev_hidden）=====\n",
        "# 这里会触发判定逻辑\n",
        "\n",
        "SKIP_LAYER_K = 8\n",
        "SKIP_THRESHOLD = 1.0  # 设为 1，理论上不会 skip\n",
        "SKIP_OUTLIER = 0.7\n",
        "\n",
        "with torch.no_grad():\n",
        "    out2_skip = model(\n",
        "        x[:, s:e],\n",
        "        past_key_values=past_kv,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=SKIP_LAYER_K,\n",
        "        skip_threshold=SKIP_THRESHOLD,\n",
        "        skip_outlier=SKIP_OUTLIER,\n",
        "        prev_hidden=prev_hidden\n",
        "    )\n",
        "\n",
        "print(f\"Skip 2nd forward logits shape: {out2_skip.logits.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "第二次 forward logits 最大差异: 0.000000\n",
            "如果 threshold=1 导致无 skip，这里也应该接近 0\n"
          ]
        }
      ],
      "source": [
        "# ===== 对比第二次 forward 的 logits =====\n",
        "diff2 = (out2_baseline.logits - out2_skip.logits).abs().max()\n",
        "print(f\"第二次 forward logits 最大差异: {diff2.item():.6f}\")\n",
        "print(f\"如果 threshold=1 导致无 skip，这里也应该接近 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "逐层 hidden states 对比:\n",
            "  Layer 0: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 1: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 2: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 3: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 4: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 5: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 6: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 7: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 8: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 9: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 10: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 11: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 12: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 13: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 14: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 15: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 16: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 17: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 18: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 19: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 20: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 21: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 22: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 23: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 24: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 25: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 26: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 27: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 28: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 29: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 30: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 31: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n",
            "  Layer 32: shape torch.Size([1, 32, 4096]), max diff = 0.000000\n"
          ]
        }
      ],
      "source": [
        "# ===== 逐层对比 hidden states =====\n",
        "print(\"逐层 hidden states 对比:\")\n",
        "for i in range(min(len(out2_baseline.hidden_states), len(out2_skip.hidden_states))):\n",
        "    h1 = out2_baseline.hidden_states[i]\n",
        "    h2 = out2_skip.hidden_states[i]\n",
        "    if h1.shape == h2.shape:\n",
        "        diff = (h1 - h2).abs().max().item()\n",
        "        print(f\"  Layer {i}: shape {h1.shape}, max diff = {diff:.6f}\")\n",
        "    else:\n",
        "        print(f\"  Layer {i}: shape mismatch! {h1.shape} vs {h2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "检查前 8 层的 cos sim（判定用）:\n",
            "prev_hidden 有 33 层\n",
            "out2_skip.hidden_states 有 33 层\n",
            "  Layer 1: cos_sim min=0.9961, max=1.0078, mean=1.0000\n",
            "  Layer 2: cos_sim min=0.9922, max=1.0078, mean=1.0000\n",
            "  Layer 3: cos_sim min=0.9883, max=1.0078, mean=1.0000\n",
            "  Layer 4: cos_sim min=0.9961, max=1.0078, mean=1.0000\n",
            "  Layer 5: cos_sim min=0.9922, max=1.0078, mean=1.0000\n",
            "  Layer 6: cos_sim min=0.9922, max=1.0078, mean=1.0000\n",
            "  Layer 7: cos_sim min=0.9961, max=1.0078, mean=1.0000\n"
          ]
        }
      ],
      "source": [
        "# ===== 检查 prev_hidden 和当前 hidden 的 cos sim =====\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(f\"检查前 {SKIP_LAYER_K} 层的 cos sim（判定用）:\")\n",
        "print(f\"prev_hidden 有 {len(prev_hidden)} 层\")\n",
        "print(f\"out2_skip.hidden_states 有 {len(out2_skip.hidden_states)} 层\")\n",
        "\n",
        "# 注意: prev_hidden 是完整序列，out2_skip.hidden_states 是当前 block\n",
        "# 需要对齐位置\n",
        "for layer in range(1, min(SKIP_LAYER_K, len(out2_skip.hidden_states))):\n",
        "    # prev_hidden[layer] 的 [s:e] 对应当前 block\n",
        "    h_prev = prev_hidden[layer][:, s:e, :]  # 上一次的当前 block 位置\n",
        "    h_curr = out2_skip.hidden_states[layer]  # 当前的\n",
        "    \n",
        "    if h_prev.shape == h_curr.shape:\n",
        "        # 计算每个 token 的 cos sim\n",
        "        cos_sims = F.cosine_similarity(h_prev, h_curr, dim=-1)  # (B, L)\n",
        "        print(f\"  Layer {layer}: cos_sim min={cos_sims.min():.4f}, max={cos_sims.max():.4f}, mean={cos_sims.mean():.4f}\")\n",
        "    else:\n",
        "        print(f\"  Layer {layer}: shape mismatch! {h_prev.shape} vs {h_curr.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "更新后 x 中非 MASK token 数量: 51\n"
          ]
        }
      ],
      "source": [
        "# ===== 模拟多步迭代：更新 x 后继续 forward =====\n",
        "# 这才是真正的生成过程\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 用 baseline 的 logits 更新 x（简单 argmax）\n",
        "x_baseline = x.clone()\n",
        "x_skip = x.clone()\n",
        "\n",
        "# 从 logits 获取预测的 token\n",
        "pred_tokens = out_baseline.logits[:, s:e, :].argmax(dim=-1)  # (1, 32)\n",
        "\n",
        "# 只更新部分位置（模拟 threshold=0.9 的行为）\n",
        "# 这里简化：更新所有 [MASK] 位置\n",
        "mask_positions = (x_baseline[:, s:e] == mask_id)\n",
        "x_baseline[:, s:e] = torch.where(mask_positions, pred_tokens, x_baseline[:, s:e])\n",
        "x_skip[:, s:e] = torch.where(mask_positions, pred_tokens, x_skip[:, s:e])\n",
        "\n",
        "print(f\"更新后 x 中非 MASK token 数量: {(x_baseline != mask_id).sum().item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2 Baseline logits shape: torch.Size([1, 32, 126464])\n",
            "Step 2 Skip logits shape: torch.Size([1, 32, 126464])\n"
          ]
        }
      ],
      "source": [
        "# ===== Step 2: 用更新后的 x 再跑一次 =====\n",
        "# Baseline\n",
        "with torch.no_grad():\n",
        "    out3_baseline = model(\n",
        "        x_baseline[:, s:e],\n",
        "        past_key_values=out2_baseline.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "# TokenSkip（用 step 1 的 hidden states 作为 prev_hidden）\n",
        "prev_hidden_step2 = out2_skip.hidden_states  # 注意：这只是当前 block 的 hidden states\n",
        "with torch.no_grad():\n",
        "    out3_skip = model(\n",
        "        x_skip[:, s:e],\n",
        "        past_key_values=out2_skip.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=SKIP_LAYER_K,\n",
        "        skip_threshold=SKIP_THRESHOLD,\n",
        "        skip_outlier=SKIP_OUTLIER,\n",
        "        prev_hidden=prev_hidden_step2\n",
        "    )\n",
        "\n",
        "print(f\"Step 2 Baseline logits shape: {out3_baseline.logits.shape}\")\n",
        "print(f\"Step 2 Skip logits shape: {out3_skip.logits.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2 logits 最大差异: 0.000000\n",
            "\n",
            "Step 2 逐层 hidden states 对比:\n",
            "  Layer 0: max diff = 0.000000\n",
            "  Layer 1: max diff = 0.000000\n",
            "  Layer 2: max diff = 0.000000\n",
            "  Layer 3: max diff = 0.000000\n",
            "  Layer 4: max diff = 0.000000\n",
            "  Layer 5: max diff = 0.000000\n",
            "  Layer 6: max diff = 0.000000\n",
            "  Layer 7: max diff = 0.000000\n",
            "  Layer 8: max diff = 0.000000\n",
            "  Layer 9: max diff = 0.000000\n"
          ]
        }
      ],
      "source": [
        "# ===== 对比 Step 2 的结果 =====\n",
        "diff3 = (out3_baseline.logits - out3_skip.logits).abs().max()\n",
        "print(f\"Step 2 logits 最大差异: {diff3.item():.6f}\")\n",
        "\n",
        "# 检查 hidden states 差异\n",
        "print(\"\\nStep 2 逐层 hidden states 对比:\")\n",
        "for i in range(min(10, len(out3_baseline.hidden_states))):  # 只看前 10 层\n",
        "    h1 = out3_baseline.hidden_states[i]\n",
        "    h2 = out3_skip.hidden_states[i]\n",
        "    if h1.shape == h2.shape:\n",
        "        diff = (h1 - h2).abs().max().item()\n",
        "        print(f\"  Layer {i}: max diff = {diff:.6f}\")\n",
        "    else:\n",
        "        print(f\"  Layer {i}: shape mismatch! {h1.shape} vs {h2.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2 cos sim（输入已变化，不再是纯 MASK）:\n",
            "  Layer 1: cos_sim min=0.8086, max=0.9180, mean=0.8828\n",
            "  Layer 2: cos_sim min=0.8008, max=0.9336, mean=0.8945\n",
            "  Layer 3: cos_sim min=0.7969, max=0.9375, mean=0.8945\n",
            "  Layer 4: cos_sim min=0.7930, max=0.9375, mean=0.8945\n",
            "  Layer 5: cos_sim min=0.8203, max=0.9336, mean=0.8984\n",
            "  Layer 6: cos_sim min=0.8242, max=0.9414, mean=0.8906\n",
            "  Layer 7: cos_sim min=0.8047, max=0.9453, mean=0.8867\n"
          ]
        }
      ],
      "source": [
        "# ===== 检查 Step 2 的 cos sim（输入变化后）=====\n",
        "print(f\"Step 2 cos sim（输入已变化，不再是纯 MASK）:\")\n",
        "\n",
        "for layer in range(1, min(SKIP_LAYER_K, len(out3_skip.hidden_states))):\n",
        "    h_prev = prev_hidden_step2[layer]  # step 1 的 hidden states\n",
        "    h_curr = out3_skip.hidden_states[layer]  # step 2 的 hidden states\n",
        "    \n",
        "    if h_prev.shape == h_curr.shape:\n",
        "        cos_sims = F.cosine_similarity(h_prev, h_curr, dim=-1)\n",
        "        print(f\"  Layer {layer}: cos_sim min={cos_sims.min():.4f}, max={cos_sims.max():.4f}, mean={cos_sims.mean():.4f}\")\n",
        "    else:\n",
        "        print(f\"  Layer {layer}: shape mismatch! {h_prev.shape} vs {h_curr.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "测试 threshold=0.95（会真正 skip 一些 token）\n",
            "============================================================\n",
            "与 Baseline 的 logits 最大差异: 0.000000\n",
            "\n",
            "Hidden states 数量: baseline=33, skip=33\n",
            "  Layer 0: baseline=torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096])\n",
            "  Layer 1: baseline=torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096])\n",
            "  Layer 2: baseline=torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096])\n",
            "  Layer 3: baseline=torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096])\n",
            "  Layer 4: baseline=torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096])\n"
          ]
        }
      ],
      "source": [
        "# ===== 测试真正的 skip（threshold=0.95）=====\n",
        "print(\"=\" * 60)\n",
        "print(\"测试 threshold=0.95（会真正 skip 一些 token）\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "SKIP_THRESHOLD_REAL = 0.95\n",
        "\n",
        "with torch.no_grad():\n",
        "    out3_skip_real = model(\n",
        "        x_skip[:, s:e],\n",
        "        past_key_values=out2_skip.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=SKIP_LAYER_K,\n",
        "        skip_threshold=SKIP_THRESHOLD_REAL,\n",
        "        skip_outlier=SKIP_OUTLIER,\n",
        "        prev_hidden=prev_hidden_step2\n",
        "    )\n",
        "\n",
        "diff_real = (out3_baseline.logits - out3_skip_real.logits).abs().max()\n",
        "print(f\"与 Baseline 的 logits 最大差异: {diff_real.item():.6f}\")\n",
        "\n",
        "# 检查 hidden states shape（如果有 skip，可能会不同）\n",
        "print(f\"\\nHidden states 数量: baseline={len(out3_baseline.hidden_states)}, skip={len(out3_skip_real.hidden_states)}\")\n",
        "for i in range(min(5, len(out3_skip_real.hidden_states))):\n",
        "    print(f\"  Layer {i}: baseline={out3_baseline.hidden_states[i].shape}, skip={out3_skip_real.hidden_states[i].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "调试汇总\n",
            "============================================================\n",
            "Step 0 (初始 forward):  diff = 0 (prev_hidden=None)\n",
            "Step 1 (threshold=1):   diff = 0.000000\n",
            "Step 2 (threshold=1):   diff = 0.000000\n",
            "Step 2 (threshold=0.95): diff = 0.000000\n",
            "\n",
            "如果 threshold=1 时 diff > 0，说明双 loop 逻辑有 bug\n",
            "如果 threshold=0.95 时 diff > 0 但输出合理，说明 skip 在工作\n"
          ]
        }
      ],
      "source": [
        "# ===== 汇总 =====\n",
        "print(\"=\" * 60)\n",
        "print(\"调试汇总\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Step 0 (初始 forward):  diff = 0 (prev_hidden=None)\")\n",
        "print(f\"Step 1 (threshold=1):   diff = {diff2.item():.6f}\")\n",
        "print(f\"Step 2 (threshold=1):   diff = {diff3.item():.6f}\")\n",
        "print(f\"Step 2 (threshold=0.95): diff = {diff_real.item():.6f}\")\n",
        "print()\n",
        "print(\"如果 threshold=1 时 diff > 0，说明双 loop 逻辑有 bug\")\n",
        "print(\"如果 threshold=0.95 时 diff > 0 但输出合理，说明 skip 在工作\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "完备 Trace：追踪模型内部执行\n",
            "============================================================\n",
            "Tracer 已创建，开始追踪...\n"
          ]
        }
      ],
      "source": [
        "# ===== 完备 Trace：追踪双 loop 逻辑的实际执行 =====\n",
        "# 用 hook 追踪每一层的 hidden state，找出问题\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"完备 Trace：追踪模型内部执行\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "class LayerTracer:\n",
        "    \"\"\"用 hook 追踪每一层的 hidden state\"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.traces = {}  # layer_idx -> hidden_state\n",
        "        self.hooks = []\n",
        "        # 给每个 block 注册 forward hook\n",
        "        for i, block in enumerate(model.model.transformer.blocks):\n",
        "            hook = block.register_forward_hook(self._make_hook(i))\n",
        "            self.hooks.append(hook)\n",
        "    \n",
        "    def _make_hook(self, layer_idx):\n",
        "        def hook(module, input, output):\n",
        "            # output[0] 是 hidden state, output[1] 是 cache\n",
        "            self.traces[layer_idx] = {\n",
        "                'input_shape': input[0].shape,\n",
        "                'output_shape': output[0].shape,\n",
        "                'output': output[0].clone().detach()\n",
        "            }\n",
        "        return hook\n",
        "    \n",
        "    def clear(self):\n",
        "        self.traces = {}\n",
        "    \n",
        "    def remove_hooks(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "        self.hooks = []\n",
        "\n",
        "# 创建 tracer\n",
        "tracer_baseline = LayerTracer(model)\n",
        "tracer_skip = LayerTracer(model)\n",
        "\n",
        "print(\"Tracer 已创建，开始追踪...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline 追踪完成，收集了 32 层\n",
            "TokenSkip 追踪完成，收集了 32 层\n"
          ]
        }
      ],
      "source": [
        "# ===== 用 Tracer 跑一次 forward，对比每层输入/输出形状 =====\n",
        "# 关键：如果 skip 生效，Loop 2 的层应该看到不同的 input_shape\n",
        "\n",
        "# 重新初始化\n",
        "x_test = x.clone()\n",
        "prev_hidden_test = out_baseline.hidden_states  # 用第一次的 hidden states\n",
        "\n",
        "# Baseline\n",
        "tracer_baseline.clear()\n",
        "with torch.no_grad():\n",
        "    out_trace_baseline = model(\n",
        "        x_test[:, s:e],\n",
        "        past_key_values=out_baseline.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "baseline_traces = {k: v.copy() for k, v in tracer_baseline.traces.items()}\n",
        "print(f\"Baseline 追踪完成，收集了 {len(baseline_traces)} 层\")\n",
        "\n",
        "# TokenSkip (threshold=0.95，应该触发 skip)\n",
        "tracer_skip.clear()\n",
        "# 注意：需要重新创建 tracer，因为同一个 model\n",
        "tracer_baseline.remove_hooks()\n",
        "tracer_skip = LayerTracer(model)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_trace_skip = model(\n",
        "        x_test[:, s:e],\n",
        "        past_key_values=out_baseline.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=8,\n",
        "        skip_threshold=0.95,  # 设为 0.95，应该触发 skip\n",
        "        skip_outlier=0.7,\n",
        "        prev_hidden=prev_hidden_test\n",
        "    )\n",
        "\n",
        "skip_traces = {k: v.copy() for k, v in tracer_skip.traces.items()}\n",
        "print(f\"TokenSkip 追踪完成，收集了 {len(skip_traces)} 层\")\n",
        "tracer_skip.remove_hooks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "逐层 input/output shape 对比:\n",
            "如果 skip 生效，Layer 8+ 的 input_shape 应该 < 32（部分 token 被踢出）\n",
            "\n",
            "Layer  0: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  1: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  2: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  3: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  4: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  5: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  6: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  7: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096])\n",
            "Layer  8: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) <-- split_layer (判定点) *** DIFF ***\n",
            "Layer  9: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 10: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 11: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 12: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 13: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 14: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 15: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 16: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 17: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 18: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 19: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 20: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 21: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 22: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 23: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 24: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 25: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 26: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 27: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 28: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 29: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 30: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n",
            "Layer 31: baseline=torch.Size([1, 32, 4096]) -> torch.Size([1, 32, 4096]), skip=torch.Size([1, 19, 4096]) -> torch.Size([1, 19, 4096]) *** DIFF ***\n"
          ]
        }
      ],
      "source": [
        "# ===== 逐层对比：找出 skip 是否生效 =====\n",
        "print(\"逐层 input/output shape 对比:\")\n",
        "print(\"如果 skip 生效，Layer 8+ 的 input_shape 应该 < 32（部分 token 被踢出）\")\n",
        "print()\n",
        "\n",
        "SKIP_LAYER_K_TEST = 8\n",
        "for layer in range(32):\n",
        "    b = baseline_traces.get(layer, {})\n",
        "    sk = skip_traces.get(layer, {})\n",
        "    \n",
        "    b_in = b.get('input_shape', 'N/A')\n",
        "    b_out = b.get('output_shape', 'N/A')\n",
        "    sk_in = sk.get('input_shape', 'N/A')\n",
        "    sk_out = sk.get('output_shape', 'N/A')\n",
        "    \n",
        "    marker = \"\"\n",
        "    if layer == SKIP_LAYER_K_TEST:\n",
        "        marker = \" <-- split_layer (判定点)\"\n",
        "    if sk_in != b_in:\n",
        "        marker += \" *** DIFF ***\"\n",
        "    \n",
        "    print(f\"Layer {layer:2d}: baseline={b_in} -> {b_out}, skip={sk_in} -> {sk_out}{marker}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "手动复现判定逻辑\n",
            "============================================================\n",
            "prev_hidden[0].shape = torch.Size([1, 147, 4096])\n",
            "当前 block 范围: [19, 51)\n",
            "block_length = 32\n",
            "\n",
            "检查 modeling_llada.py 中的判定逻辑:\n",
            "代码中 prev_hidden[layer] 是完整序列，而 all_hidden_states[layer] 是当前 block\n",
            "这可能是 bug！需要对 prev_hidden 做切片\n"
          ]
        }
      ],
      "source": [
        "# ===== 手动复现判定逻辑，检查为什么 skip 没生效 =====\n",
        "print(\"=\" * 60)\n",
        "print(\"手动复现判定逻辑\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 关键：prev_hidden 的形状和当前 block 的对应关系\n",
        "print(f\"prev_hidden[0].shape = {prev_hidden_test[0].shape}\")  # 完整序列 [1, 147, 4096]\n",
        "print(f\"当前 block 范围: [{s}, {e})\")\n",
        "print(f\"block_length = {e - s}\")\n",
        "\n",
        "# 模型内部判定时，x 的形状是 [1, 32, 4096]（当前 block）\n",
        "# 但 prev_hidden 的形状是 [1, 147, 4096]（完整序列）\n",
        "# 问题：模型内部是否正确切片了 prev_hidden？\n",
        "\n",
        "print()\n",
        "print(\"检查 modeling_llada.py 中的判定逻辑:\")\n",
        "print(\"代码中 prev_hidden[layer] 是完整序列，而 all_hidden_states[layer] 是当前 block\")\n",
        "print(\"这可能是 bug！需要对 prev_hidden 做切片\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "正确模拟 generate 流程\n",
            "============================================================\n",
            "Step 0: 初始 forward, x shape=torch.Size([1, 147]), hidden_states[0] shape=torch.Size([1, 147, 4096])\n",
            "更新后 x_gen 中非 MASK token 数量: 147\n"
          ]
        }
      ],
      "source": [
        "# ===== 正确模拟 generate 流程 =====\n",
        "print(\"=\" * 60)\n",
        "print(\"正确模拟 generate 流程\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 0: 初始 forward（完整序列）- 用于建立 KV cache\n",
        "x_gen = x.clone()\n",
        "with torch.no_grad():\n",
        "    out_init = model(x_gen, use_cache=True, output_hidden_states=True)\n",
        "past_kv_gen = out_init.past_key_values\n",
        "print(f\"Step 0: 初始 forward, x shape={x_gen.shape}, hidden_states[0] shape={out_init.hidden_states[0].shape}\")\n",
        "\n",
        "# 更新 x（模拟第一次采样）\n",
        "logits_full = out_init.logits\n",
        "x0 = logits_full.argmax(dim=-1)\n",
        "mask_idx = (x_gen == mask_id)\n",
        "x_gen = torch.where(mask_idx, x0, x_gen)\n",
        "print(f\"更新后 x_gen 中非 MASK token 数量: {(x_gen != mask_id).sum().item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Refinement Step 1\n",
            "============================================================\n",
            "Step 1: prev_hidden=None, diff=0.000000 (应该=0)\n",
            "out1_skip.hidden_states[0].shape = torch.Size([1, 32, 4096])\n",
            "prev_hidden_step1 有 33 层, shape=torch.Size([1, 32, 4096])\n"
          ]
        }
      ],
      "source": [
        "# ===== Refinement Step 1（Baseline vs TokenSkip）=====\n",
        "# 关键：prev_hidden = None，这一步不会 skip\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Refinement Step 1\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 构造 replace_position\n",
        "replace_position_gen = torch.zeros_like(x_gen, dtype=torch.bool)\n",
        "replace_position_gen[:, s:e] = True\n",
        "\n",
        "# Baseline\n",
        "with torch.no_grad():\n",
        "    out1_base = model(\n",
        "        x_gen[:, s:e],\n",
        "        past_key_values=past_kv_gen,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position_gen,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "# TokenSkip（prev_hidden=None，不会 skip）\n",
        "with torch.no_grad():\n",
        "    out1_skip = model(\n",
        "        x_gen[:, s:e],\n",
        "        past_key_values=past_kv_gen,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position_gen,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=8,\n",
        "        skip_threshold=0.95,\n",
        "        skip_outlier=0.7,\n",
        "        prev_hidden=None  # 关键：第一次是 None\n",
        "    )\n",
        "\n",
        "diff1 = (out1_base.logits - out1_skip.logits).abs().max()\n",
        "print(f\"Step 1: prev_hidden=None, diff={diff1.item():.6f} (应该=0)\")\n",
        "print(f\"out1_skip.hidden_states[0].shape = {out1_skip.hidden_states[0].shape}\")\n",
        "\n",
        "# 这个 hidden_states 会作为下一步的 prev_hidden\n",
        "prev_hidden_step1 = out1_skip.hidden_states\n",
        "print(f\"prev_hidden_step1 有 {len(prev_hidden_step1)} 层, shape={prev_hidden_step1[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Refinement Step 2（skip 应该生效）\n",
            "============================================================\n",
            "更新后 x_gen 中非 MASK token 数量: 147\n",
            "Step 2 (threshold=1):    diff=0.000000 (应该=0)\n",
            "Step 2 (threshold=0.95): diff=26.000000 (如果有 skip，应该>0)\n"
          ]
        }
      ],
      "source": [
        "# ===== Refinement Step 2（应该触发 skip）=====\n",
        "# 关键：prev_hidden 形状是 [1, 32, 4096]（当前 block）\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Refinement Step 2（skip 应该生效）\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 更新 x_gen（模拟采样）\n",
        "pred1 = out1_base.logits.argmax(dim=-1)\n",
        "mask_blk = (x_gen[:, s:e] == mask_id)\n",
        "x_gen[:, s:e] = torch.where(mask_blk, pred1, x_gen[:, s:e])\n",
        "print(f\"更新后 x_gen 中非 MASK token 数量: {(x_gen != mask_id).sum().item()}\")\n",
        "\n",
        "# Baseline\n",
        "with torch.no_grad():\n",
        "    out2_base = model(\n",
        "        x_gen[:, s:e],\n",
        "        past_key_values=out1_base.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position_gen,\n",
        "        output_hidden_states=True\n",
        "    )\n",
        "\n",
        "# TokenSkip（threshold=1，不应该 skip）\n",
        "with torch.no_grad():\n",
        "    out2_skip_no = model(\n",
        "        x_gen[:, s:e],\n",
        "        past_key_values=out1_skip.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position_gen,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=8,\n",
        "        skip_threshold=1.0,  # threshold=1，不 skip\n",
        "        skip_outlier=0.7,\n",
        "        prev_hidden=prev_hidden_step1\n",
        "    )\n",
        "\n",
        "# TokenSkip（threshold=0.95，应该 skip）\n",
        "with torch.no_grad():\n",
        "    out2_skip_yes = model(\n",
        "        x_gen[:, s:e],\n",
        "        past_key_values=out1_skip.past_key_values,\n",
        "        use_cache=True,\n",
        "        replace_position=replace_position_gen,\n",
        "        output_hidden_states=True,\n",
        "        skip_layer_k=8,\n",
        "        skip_threshold=0.95,  # threshold=0.95，可能 skip\n",
        "        skip_outlier=0.7,\n",
        "        prev_hidden=prev_hidden_step1\n",
        "    )\n",
        "\n",
        "diff2_no = (out2_base.logits - out2_skip_no.logits).abs().max()\n",
        "diff2_yes = (out2_base.logits - out2_skip_yes.logits).abs().max()\n",
        "\n",
        "print(f\"Step 2 (threshold=1):    diff={diff2_no.item():.6f} (应该=0)\")\n",
        "print(f\"Step 2 (threshold=0.95): diff={diff2_yes.item():.6f} (如果有 skip，应该>0)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "手动复现模型内部判定逻辑\n",
            "============================================================\n",
            "prev_hidden_step1 形状: torch.Size([1, 32, 4096])\n",
            "out2_skip_no.hidden_states 形状: torch.Size([1, 32, 4096])\n",
            "\n",
            "判定结果:\n",
            "  稳定（会 skip）的 token 数量: 32\n",
            "  不稳定（继续计算）的 token 数量: 0\n",
            "\n",
            "前 5 个 token 的 cos_sim:\n",
            "  Token 0: ['0.9961', '1.0000', '1.0078', '1.0000', '1.0000', '1.0078', '1.0000'], min=0.9961, mean=1.0017\n",
            "  Token 1: ['1.0000', '1.0000', '1.0078', '1.0000', '1.0000', '1.0000', '0.9922'], min=0.9922, mean=1.0000\n",
            "  Token 2: ['1.0078', '1.0000', '0.9961', '0.9961', '1.0000', '0.9922', '1.0000'], min=0.9922, mean=0.9989\n",
            "  Token 3: ['1.0000', '1.0000', '0.9961', '0.9961', '0.9961', '0.9961', '1.0000'], min=0.9961, mean=0.9978\n",
            "  Token 4: ['1.0000', '1.0078', '1.0000', '0.9961', '1.0000', '1.0000', '1.0000'], min=0.9961, mean=1.0006\n"
          ]
        }
      ],
      "source": [
        "# ===== 手动计算判定逻辑应该看到的 cos_sim =====\n",
        "print(\"=\" * 60)\n",
        "print(\"手动复现模型内部判定逻辑\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 模型内部：\n",
        "# - prev_hidden[layer] 形状 [1, 32, 4096]（上一步的当前 block hidden states）\n",
        "# - all_hidden_states[layer] 形状 [1, 32, 4096]（当前 block 的 hidden states）\n",
        "\n",
        "# 我们需要比较 prev_hidden_step1 和 out2_skip_no 的前 K 层 hidden states\n",
        "\n",
        "print(f\"prev_hidden_step1 形状: {prev_hidden_step1[0].shape}\")\n",
        "print(f\"out2_skip_no.hidden_states 形状: {out2_skip_no.hidden_states[0].shape}\")\n",
        "print()\n",
        "\n",
        "SKIP_LAYER_K_SIM = 8\n",
        "SKIP_THRESHOLD_SIM = 0.95\n",
        "SKIP_OUTLIER_SIM = 0.7\n",
        "\n",
        "# 模拟判定\n",
        "L = 32  # block_length\n",
        "active_mask = torch.ones(L, dtype=torch.bool)\n",
        "all_cos_sims = []\n",
        "\n",
        "for j in range(L):\n",
        "    cos_sims_j = []\n",
        "    for layer in range(1, SKIP_LAYER_K_SIM):\n",
        "        h1 = prev_hidden_step1[layer][0, j, :]  # 上一步的 token j\n",
        "        h2 = out2_skip_no.hidden_states[layer][0, j, :]  # 当前的 token j\n",
        "        cos = F.cosine_similarity(h1.unsqueeze(0), h2.unsqueeze(0), dim=-1).item()\n",
        "        cos_sims_j.append(cos)\n",
        "    \n",
        "    all_cos_sims.append(cos_sims_j)\n",
        "    \n",
        "    min_cos = min(cos_sims_j)\n",
        "    mean_cos = sum(cos_sims_j) / len(cos_sims_j)\n",
        "    stable = min_cos >= SKIP_OUTLIER_SIM and mean_cos >= SKIP_THRESHOLD_SIM\n",
        "    active_mask[j] = not stable  # 稳定的标记为 False（踢出）\n",
        "\n",
        "print(f\"判定结果:\")\n",
        "print(f\"  稳定（会 skip）的 token 数量: {(~active_mask).sum().item()}\")\n",
        "print(f\"  不稳定（继续计算）的 token 数量: {active_mask.sum().item()}\")\n",
        "print()\n",
        "\n",
        "# 打印几个 token 的 cos_sim\n",
        "print(\"前 5 个 token 的 cos_sim:\")\n",
        "for j in range(min(5, L)):\n",
        "    print(f\"  Token {j}: {[f'{c:.4f}' for c in all_cos_sims[j]]}, min={min(all_cos_sims[j]):.4f}, mean={sum(all_cos_sims[j])/len(all_cos_sims[j]):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "所有 token 的 cos_sim 统计\n",
            "============================================================\n",
            "min(cos_sim) 分布:\n",
            "  min=0.9883, max=1.0000, mean=0.9948\n",
            "mean(cos_sim) 分布:\n",
            "  min=0.9967, max=1.0045, mean=1.0000\n",
            "\n",
            "判定条件: min >= 0.7 AND mean >= 0.95\n",
            "满足条件的 token 数量: 32\n",
            "\n",
            "有 32 个 token 的 mean >= threshold\n"
          ]
        }
      ],
      "source": [
        "# ===== 统计所有 token 的 cos_sim 分布 =====\n",
        "print(\"=\" * 60)\n",
        "print(\"所有 token 的 cos_sim 统计\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "all_min_cos = [min(c) for c in all_cos_sims]\n",
        "all_mean_cos = [sum(c)/len(c) for c in all_cos_sims]\n",
        "\n",
        "print(f\"min(cos_sim) 分布:\")\n",
        "print(f\"  min={min(all_min_cos):.4f}, max={max(all_min_cos):.4f}, mean={np.mean(all_min_cos):.4f}\")\n",
        "print(f\"mean(cos_sim) 分布:\")\n",
        "print(f\"  min={min(all_mean_cos):.4f}, max={max(all_mean_cos):.4f}, mean={np.mean(all_mean_cos):.4f}\")\n",
        "print()\n",
        "print(f\"判定条件: min >= {SKIP_OUTLIER_SIM} AND mean >= {SKIP_THRESHOLD_SIM}\")\n",
        "print(f\"满足条件的 token 数量: {sum(1 for m, a in zip(all_min_cos, all_mean_cos) if m >= SKIP_OUTLIER_SIM and a >= SKIP_THRESHOLD_SIM)}\")\n",
        "print()\n",
        "\n",
        "# 如果没有 token 满足条件，说明输入变化太大，cos_sim 下降\n",
        "if all(a < SKIP_THRESHOLD_SIM for a in all_mean_cos):\n",
        "    print(\"结论: 输入变化后，所有 token 的 cos_sim 都低于 threshold，没有 skip 发生\")\n",
        "    print(\"这是预期行为！因为输入从 [MASK] 变成了预测的 token\")\n",
        "else:\n",
        "    print(f\"有 {sum(1 for a in all_mean_cos if a >= SKIP_THRESHOLD_SIM)} 个 token 的 mean >= threshold\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "最终诊断\n",
            "============================================================\n",
            "1. 形状对齐检查:\n",
            "   prev_hidden shape: torch.Size([1, 32, 4096])\n",
            "   current hidden shape: torch.Size([1, 32, 4096])\n",
            "   ✓ 形状一致（都是当前 block 的 hidden states）\n",
            "\n",
            "2. 判定逻辑检查:\n",
            "   threshold=1.0 时 diff: 0.000000\n",
            "   ✓ threshold=1 时完全退化到 baseline（正确）\n",
            "\n",
            "3. Skip 触发检查:\n",
            "   threshold=0.95 时 diff: 26.000000\n",
            "   ✓ 有 token 被 skip，输出与 baseline 不同\n",
            "\n",
            "4. 建议:\n",
            "   - 在真实生成场景中，只有当输入变化很小时 skip 才会触发\n",
            "   - 可以考虑降低 threshold（如 0.8）来增加 skip 率\n",
            "   - 或者在连续多个 step 输入不变的情况下测试 skip\n"
          ]
        }
      ],
      "source": [
        "# ===== 最终诊断 =====\n",
        "print(\"=\" * 60)\n",
        "print(\"最终诊断\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"1. 形状对齐检查:\")\n",
        "print(f\"   prev_hidden shape: {prev_hidden_step1[0].shape}\")\n",
        "print(f\"   current hidden shape: {out2_skip_no.hidden_states[0].shape}\")\n",
        "print(f\"   ✓ 形状一致（都是当前 block 的 hidden states）\")\n",
        "print()\n",
        "\n",
        "print(\"2. 判定逻辑检查:\")\n",
        "print(f\"   threshold=1.0 时 diff: {diff2_no.item():.6f}\")\n",
        "if diff2_no.item() == 0:\n",
        "    print(\"   ✓ threshold=1 时完全退化到 baseline（正确）\")\n",
        "else:\n",
        "    print(\"   ✗ BUG: threshold=1 时应该与 baseline 一致！\")\n",
        "print()\n",
        "\n",
        "print(f\"3. Skip 触发检查:\")\n",
        "print(f\"   threshold=0.95 时 diff: {diff2_yes.item():.6f}\")\n",
        "if diff2_yes.item() == 0:\n",
        "    print(\"   cos_sim 统计显示所有 token 都不满足 skip 条件\")\n",
        "    print(\"   这是因为输入从 [MASK] 变成了预测 token，hidden states 变化较大\")\n",
        "    print(\"   这是预期行为，不是 bug\")\n",
        "else:\n",
        "    print(\"   ✓ 有 token 被 skip，输出与 baseline 不同\")\n",
        "print()\n",
        "\n",
        "print(\"4. 建议:\")\n",
        "print(\"   - 在真实生成场景中，只有当输入变化很小时 skip 才会触发\")\n",
        "print(\"   - 可以考虑降低 threshold（如 0.8）来增加 skip 率\")\n",
        "print(\"   - 或者在连续多个 step 输入不变的情况下测试 skip\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dllm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
