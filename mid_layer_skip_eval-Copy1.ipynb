{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KV Reuse Evaluation\n",
    "\n",
    "在 GSM8K 上评测 Dual Cache + KV Reuse 优化。\n",
    "\n",
    "**KV Reuse 原理：**\n",
    "- 比较当前 step 与上一 step 的 hidden states 的 cosine similarity\n",
    "- 对于相似度 >= threshold 的 token，复用上一 step 的 K/V\n",
    "- Q/Attention/FFN/logits 仍然重新计算\n",
    "- 被复用的 token 下一步强制更新（防止误差累积）\n",
    "\n",
    "**实验配置:**\n",
    "1. Baseline: Dual Cache（不使用 KV reuse）\n",
    "2. Dual Cache + 不同 `similarity_threshold` (0.60, 0.70, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA RTX A5000\n",
      "Total VRAM: 22.06 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Set GPU (modify as needed)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
    "\n",
    "# Environment settings\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "os.environ['HF_ALLOW_CODE_EVAL'] = '1'\n",
    "os.environ['HF_DATASETS_TRUST_REMOTE_CODE'] = 'true'\n",
    "\n",
    "# Change to llada directory\n",
    "os.chdir('llada')\n",
    "\n",
    "# Create log directory\n",
    "os.makedirs('nlogs', exist_ok=True)\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 快速测试 (limit=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: baseline\n",
      "Log file: nlogs/gsm8k_baseline_20260123_020654.log\n",
      "============================================================\n",
      "Last 10 lines:\n",
      "Total number of tokens generated: 3695\n",
      "Total time taken: 68.66974472999573 seconds\n",
      "Tokens per second: 53.808265686035156\n",
      "Total NFE is 923\n",
      "llada_dist (model_path=GSAI-ML/LLaDA-8B-Instruct,gen_length=128,steps=32,block_length=32,threshold=0.9,use_cache=True,dual_cache=True,show_speed=True,mid_layer_skip=False), gen_kwargs: (None), limit: 30.0, num_fewshot: 3, batch_size: 1\n",
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     3|exact_match|↑  |0.5333|±  |0.0926|\n",
      "|     |       |strict-match    |     3|exact_match|↑  |0.4000|±  |0.0910|\n",
      "\n",
      "\n",
      "============================================================\n",
      "Running: kv_reuse_th070\n",
      "Log file: nlogs/gsm8k_kv_reuse_th070_20260123_020842.log\n",
      "============================================================\n",
      "Last 10 lines:\n",
      "Total number of tokens generated: 3666\n",
      "Total time taken: 74.38229727745056 seconds\n",
      "Tokens per second: 49.28592300415039\n",
      "Total NFE is 920\n",
      "llada_dist (model_path=GSAI-ML/LLaDA-8B-Instruct,gen_length=128,steps=32,block_length=32,threshold=0.9,use_cache=True,dual_cache=True,show_speed=True,mid_layer_skip=True,early_exit_threshold=0.7), gen_kwargs: (None), limit: 30.0, num_fewshot: 3, batch_size: 1\n",
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     3|exact_match|↑  |0.4333|±  |0.0920|\n",
      "|     |       |strict-match    |     3|exact_match|↑  |0.3667|±  |0.0895|\n",
      "\n",
      "\n",
      "============================================================\n",
      "Running: kv_reuse_th080\n",
      "Log file: nlogs/gsm8k_kv_reuse_th080_20260123_021034.log\n",
      "============================================================\n",
      "Last 10 lines:\n",
      "Total number of tokens generated: 3664\n",
      "Total time taken: 74.32885479927063 seconds\n",
      "Tokens per second: 49.29444885253906\n",
      "Total NFE is 916\n",
      "llada_dist (model_path=GSAI-ML/LLaDA-8B-Instruct,gen_length=128,steps=32,block_length=32,threshold=0.9,use_cache=True,dual_cache=True,show_speed=True,mid_layer_skip=True,early_exit_threshold=0.8), gen_kwargs: (None), limit: 30.0, num_fewshot: 3, batch_size: 1\n",
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     3|exact_match|↑  |0.4667|±  |0.0926|\n",
      "|     |       |strict-match    |     3|exact_match|↑  |0.4000|±  |0.0910|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "task = \"gsm8k\"\n",
    "fewshot = 3\n",
    "limit = 30\n",
    "gpu = 1\n",
    "\n",
    "# (threshold, name)\n",
    "experiments = [\n",
    "    (None, \"baseline\"),\n",
    "    (0.70, \"kv_reuse_th070\"),\n",
    "    (0.80, \"kv_reuse_th080\"),\n",
    "]\n",
    "\n",
    "for threshold, name in experiments:\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file = f\"nlogs/{task}_{name}_{timestamp}.log\"\n",
    "    \n",
    "    model_args = [\n",
    "        \"model_path='GSAI-ML/LLaDA-8B-Instruct'\",\n",
    "        \"gen_length=128\",\n",
    "        \"steps=32\",\n",
    "        \"block_length=32\",\n",
    "        \"threshold=0.9\",\n",
    "        \"use_cache=True\",\n",
    "        \"dual_cache=True\",\n",
    "        \"show_speed=True\",\n",
    "    ]\n",
    "    \n",
    "    if threshold is not None:\n",
    "        model_args.extend([\n",
    "            \"mid_layer_skip=True\",\n",
    "            f\"early_exit_threshold={threshold}\",  # Maps to similarity_threshold internally\n",
    "        ])\n",
    "    else:\n",
    "        model_args.append(\"mid_layer_skip=False\")\n",
    "    \n",
    "    cmd = f\"\"\"CUDA_VISIBLE_DEVICES={gpu} accelerate launch eval_llada.py \\\\\n",
    "        --tasks {task} --num_fewshot {fewshot} --limit {limit} \\\\\n",
    "        --confirm_run_unsafe_code --model llada_dist \\\\\n",
    "        --model_args {','.join(model_args)}\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running: {name}\")\n",
    "    print(f\"Log file: {log_file}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    with open(log_file, 'w') as f:\n",
    "        result = subprocess.run(cmd, shell=True, stdout=f, stderr=subprocess.STDOUT, text=True)\n",
    "    \n",
    "    with open(log_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        print(\"Last 10 lines:\")\n",
    "        for line in lines[-10:]:\n",
    "            print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 并行完整测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "task = \"gsm8k\"\n",
    "fewshot = 4\n",
    "\n",
    "# (threshold, gpu, name)\n",
    "configs = [\n",
    "    (None, 0, \"baseline\"),\n",
    "    (0.60, 1, \"kv_reuse_th060\"),\n",
    "    (0.70, 2, \"kv_reuse_th070\"),\n",
    "    (0.80, 3, \"kv_reuse_th080\"),\n",
    "]\n",
    "\n",
    "processes = []\n",
    "\n",
    "for threshold, gpu, name in configs:\n",
    "    log_file = f\"nlogs/kv_reuse_{task}_{name}_{datetime.datetime.now():%F_%H-%M-%S}.log\"\n",
    "    \n",
    "    skip_args = f\"dual_cache=True\"\n",
    "    if threshold is not None:\n",
    "        skip_args += f\",mid_layer_skip=True,early_exit_threshold={threshold}\"\n",
    "    else:\n",
    "        skip_args += \",mid_layer_skip=False\"\n",
    "    \n",
    "    cmd = f\"\"\"CUDA_VISIBLE_DEVICES={gpu} accelerate launch eval_llada.py \\\\\n",
    "        --tasks {task} --num_fewshot {fewshot} \\\\\n",
    "        --confirm_run_unsafe_code --model llada_dist \\\\\n",
    "        --model_args model_path='GSAI-ML/LLaDA-8B-Instruct',gen_length=256,steps=256,block_length=32,threshold=0.9,{skip_args},show_speed=True \\\\\n",
    "        --output_path evals_results/kv_reuse/gsm8k-{name} --log_samples\"\"\"\n",
    "    \n",
    "    print(f\"GPU{gpu} running: {name}\")\n",
    "    p = subprocess.Popen(cmd, shell=True, stdout=open(log_file, \"w\"), stderr=subprocess.STDOUT)\n",
    "    processes.append((p, name, log_file))\n",
    "\n",
    "print(f\"\\n{len(processes)} tasks launched, waiting...\")\n",
    "\n",
    "for p, name, log in processes:\n",
    "    p.wait()\n",
    "    print(f\"{name} finished (exit code: {p.returncode})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "log_files = sorted(glob.glob(\"nlogs/kv_reuse_gsm8k*.log\"), key=os.path.getmtime, reverse=True)\n",
    "\n",
    "print(\"KV Reuse GSM8K Results:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "results = []\n",
    "for log_file in log_files[:10]:\n",
    "    name = os.path.basename(log_file)\n",
    "    \n",
    "    with open(log_file, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Accuracy\n",
    "    acc_match = re.search(r'exact_match[,:\\|]?\\s*([\\d.]+)', content)\n",
    "    acc = float(acc_match.group(1)) * 100 if acc_match else None\n",
    "    \n",
    "    # Speed\n",
    "    speed_match = re.search(r'Tokens per second:\\s*([\\d.]+)', content)\n",
    "    speed = float(speed_match.group(1)) if speed_match else None\n",
    "    \n",
    "    # NFE\n",
    "    nfe_match = re.search(r'Total NFE is (\\d+)', content)\n",
    "    nfe = int(nfe_match.group(1)) if nfe_match else None\n",
    "    \n",
    "    # Time\n",
    "    time_match = re.search(r'Total time taken:\\s*([\\d.]+)', content)\n",
    "    time_sec = float(time_match.group(1)) if time_match else None\n",
    "    \n",
    "    # KV Reuse rate\n",
    "    kv_match = re.search(r'kv_reuse_rate=([\\d.]+)%', content)\n",
    "    kv_rate = float(kv_match.group(1)) if kv_match else None\n",
    "    \n",
    "    # Token KV reuse rate\n",
    "    tkv_match = re.search(r'token_kv_reuse_rate=([\\d.]+)%', content)\n",
    "    tkv_rate = float(tkv_match.group(1)) if tkv_match else None\n",
    "    \n",
    "    results.append({\n",
    "        'name': name,\n",
    "        'accuracy': acc,\n",
    "        'tokens_per_sec': speed,\n",
    "        'total_nfe': nfe,\n",
    "        'time_sec': time_sec,\n",
    "        'kv_reuse_rate': kv_rate,\n",
    "        'token_kv_rate': tkv_rate,\n",
    "    })\n",
    "\n",
    "print(f\"{'Name':<50} {'Acc%':<8} {'Tok/s':<10} {'NFE':<10} {'Time(s)':<10} {'KV%':<8} {'TKV%':<8}\")\n",
    "print(\"-\" * 90)\n",
    "for r in results:\n",
    "    acc_str = f\"{r['accuracy']:.2f}\" if r['accuracy'] else \"N/A\"\n",
    "    speed_str = f\"{r['tokens_per_sec']:.1f}\" if r['tokens_per_sec'] else \"N/A\"\n",
    "    nfe_str = str(r['total_nfe']) if r['total_nfe'] else \"N/A\"\n",
    "    time_str = f\"{r['time_sec']:.1f}\" if r['time_sec'] else \"N/A\"\n",
    "    kv_str = f\"{r['kv_reuse_rate']:.1f}\" if r['kv_reuse_rate'] else \"N/A\"\n",
    "    tkv_str = f\"{r['token_kv_rate']:.1f}\" if r['token_kv_rate'] else \"N/A\"\n",
    "    print(f\"{r['name']:<50} {acc_str:<8} {speed_str:<10} {nfe_str:<10} {time_str:<10} {kv_str:<8} {tkv_str:<8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 手动运行（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single experiment\n",
    "import subprocess\n",
    "import datetime\n",
    "\n",
    "threshold = 0.70\n",
    "limit = 100\n",
    "gpu = 0\n",
    "\n",
    "name = f\"manual_th{int(threshold*100)}\" if threshold else \"manual_baseline\"\n",
    "log_file = f\"nlogs/manual_kv_reuse_{name}_{datetime.datetime.now():%F_%H-%M-%S}.log\"\n",
    "\n",
    "skip_args = f\"dual_cache=True\"\n",
    "if threshold is not None:\n",
    "    skip_args += f\",mid_layer_skip=True,early_exit_threshold={threshold}\"\n",
    "else:\n",
    "    skip_args += \",mid_layer_skip=False\"\n",
    "\n",
    "cmd = f\"\"\"CUDA_VISIBLE_DEVICES={gpu} accelerate launch eval_llada.py \\\\\n",
    "    --tasks gsm8k --num_fewshot 5 --limit {limit} \\\\\n",
    "    --confirm_run_unsafe_code --model llada_dist \\\\\n",
    "    --model_args model_path='GSAI-ML/LLaDA-8B-Instruct',gen_length=256,steps=256,block_length=32,threshold=0.9,{skip_args},show_speed=True \\\\\n",
    "    --output_path evals_results/kv_reuse/manual-{name} --log_samples\"\"\"\n",
    "\n",
    "print(f\"Running: {name}\")\n",
    "print(f\"Log: {log_file}\")\n",
    "print(f\"Command: {cmd[:150]}...\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# p = subprocess.Popen(cmd, shell=True, stdout=open(log_file, \"w\"), stderr=subprocess.STDOUT)\n",
    "# p.wait()\n",
    "# print(f\"Finished (exit code: {p.returncode})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
